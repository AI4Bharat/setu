placement:
  managedCluster:
    clusterName: setu-crawl-analysis
    config:
      gceClusterConfig:
        zoneUri: asia-south1-a

jobs:
- pysparkJob:
    fileUris:
    mainPythonFileUri: your_pyspark_script.py
    properties:
      spark.executorEnv.MY_VAR1: 'default_value'
      spark.executorEnv.MY_VAR2: 'default_value'
  stepId: DOCUMENT_CLEANING
- pysparkJob:
    fileUris:
    mainPythonFileUri: your_pyspark_script.py
    properties:
      spark.executorEnv.MY_VAR1: 'default_value'
      spark.executorEnv.MY_VAR2: 'default_value'
  stepId: LID_SEGREGATION
  prerequisiteStepIds:
  - DOCUMENT_CLEANING
- pysparkJob:
    fileUris:
    mainPythonFileUri: your_pyspark_script.py
    properties:
      spark.executorEnv.MY_VAR1: 'default_value'
      spark.executorEnv.MY_VAR2: 'default_value'
  stepId: ANALYSIS
  prerequisiteStepIds:
  - DOCUMENT_CLEANING
  - LID_SEGREGATION

parameters:
  - name: MY_VAR1
    fields:
      - jobs[STEP_NAME'].pysparkJob.properties['spark.executorEnv.MY_VAR1']
  - name: MY_VAR2
    fields:
      - jobs[STEP_NAME'].pysparkJob.properties['spark.executorEnv.MY_VAR2']