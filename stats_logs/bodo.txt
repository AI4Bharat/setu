done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/56b68cf0b9ba42958f085babd3f3badf/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/56b68cf0b9ba42958f085babd3f3badf/driveroutput
jobUuid: 4b1c9090-1e75-34d6-8380-06f3c53b0596
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_bodo_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --symbol_heavy_parquets
  - gs://sangraha/spark_out/bodo/*/lid_segregation/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out/bodo/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 56b68cf0b9ba42958f085babd3f3badf
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T18:54:17.194765Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T18:53:23.533920Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T18:53:23.560467Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T18:53:23.953618Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0009/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/7f55d4e93191427c9a1ef9e49987e6c9/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/7f55d4e93191427c9a1ef9e49987e6c9/driveroutput
jobUuid: 644178df-2492-3c47-bdcf-08819186daf0
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_bodo_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeLIDStage
  - --lid_parquets
  - gs://sangraha/spark_out/bodo/*/lid_segregation/doc_lid/*/*/*.parquet
  - --cleaned_docs_parquets
  - gs://sangraha/spark_out/bodo/*/lid_segregation/doc_lid/*/*.parquet
  - --lid_viz_output
  - gs://sangraha/spark_out/bodo/visualization/dataset/lid
  - --lid_viz_gcp_bucket
  - sangraha
  - --viz_lid_stage_run_mode
  - stage
  - --viz_lid_perform_join
  - 'False'
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 7f55d4e93191427c9a1ef9e49987e6c9
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T18:55:27.239398Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T18:54:20.571968Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T18:54:20.603367Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T18:54:20.871535Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0010/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/df8d7bb1310d4517ab2a73a32cabedab/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/df8d7bb1310d4517ab2a73a32cabedab/driveroutput
jobUuid: a8a5bbfb-410a-35fd-8655-9850d98748eb
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_bodo_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeAnalysisStage
  - --analysis_doc_stats_parquets
  - gs://sangraha/spark_out/bodo/*/analysis/doc_stats/*/*/*.parquet
  - --analysis_viz_output
  - gs://sangraha/spark_out/bodo/visualization/dataset/analysis
  - --ana_viz_language
  - bodo
  - --ana_viz_gcp_bucket
  - sangraha
  - --viz_analysis_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: df8d7bb1310d4517ab2a73a32cabedab
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T18:56:33.019408Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T18:55:29.805911Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T18:55:29.832060Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T18:55:30.089279Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0011/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/d6ce786c877448a78c565d241237da34/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/d6ce786c877448a78c565d241237da34/driveroutput
jobUuid: a40f7c67-cd75-3cc5-847c-889859743ddc
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_bodo_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeFilterStage
  - --filtered_docs_parquets
  - gs://sangraha/spark_out/bodo/*/filtered_docs/filtered_docs/*/*.parquet
  - --filter_viz_output
  - gs://sangraha/spark_out/bodo/visualization/dataset/filter
  - --fil_viz_gcp_bucket
  - sangraha
  - --viz_filter_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: d6ce786c877448a78c565d241237da34
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T18:57:27.315074Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T18:56:36.510411Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T18:56:36.533459Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T18:56:36.908141Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0012/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/170eac664d43450390d153228f6f56eb/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/170eac664d43450390d153228f6f56eb/driveroutput
jobUuid: 11e0dd87-47a5-3392-b7a6-a10a9498f5f8
placement:
  clusterName: setu-debugging-50-highmem
  clusterUuid: d83f9aa0-6d42-4443-bcca-a8e58f2246c0
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_bodo_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --viz_cleaned_docs_parquets
  - gs://sangraha/spark_out_test/bodo/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --viz_symbol_heavy_parquets
  - gs://sangraha/spark_out_test/bodo/*/cleaned_docs/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out_test/bodo/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 170eac664d43450390d153228f6f56eb
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-10-02T09:05:21.088100Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-10-02T09:04:13.829551Z'
- state: SETUP_DONE
  stateStartTime: '2023-10-02T09:04:13.851379Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-10-02T09:04:14.111938Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-50-highmem-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696195790754_0029/
