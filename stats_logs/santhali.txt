done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/2e3bb6ca943c4542925e9b2ef45123a7/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/2e3bb6ca943c4542925e9b2ef45123a7/driveroutput
jobUuid: ebe8acec-7f3f-36fd-ba19-b676e0e517b6
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_santhali_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --symbol_heavy_parquets
  - gs://sangraha/spark_out/santhali/*/lid_segregation/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out/santhali/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 2e3bb6ca943c4542925e9b2ef45123a7
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T19:48:49.642072Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T19:48:02.368114Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T19:48:02.392221Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T19:48:02.793009Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0053/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/06aaebf1413248f289fbcbbf20bc824f/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/06aaebf1413248f289fbcbbf20bc824f/driveroutput
jobUuid: 2592f1ba-6151-37c1-8234-c4c414d3fb77
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_santhali_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeLIDStage
  - --lid_parquets
  - gs://sangraha/spark_out/santhali/*/lid_segregation/doc_lid/*/*/*.parquet
  - --cleaned_docs_parquets
  - gs://sangraha/spark_out/santhali/*/lid_segregation/doc_lid/*/*.parquet
  - --lid_viz_output
  - gs://sangraha/spark_out/santhali/visualization/dataset/lid
  - --lid_viz_gcp_bucket
  - sangraha
  - --viz_lid_stage_run_mode
  - stage
  - --viz_lid_perform_join
  - 'False'
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 06aaebf1413248f289fbcbbf20bc824f
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T19:49:49.714840Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T19:48:53.158438Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T19:48:53.183463Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T19:48:53.510887Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0054/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/1417d4f6ec0d47b18b36c0b1048b3b16/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/1417d4f6ec0d47b18b36c0b1048b3b16/driveroutput
jobUuid: 58c54eb5-f007-38ca-b90f-9566496e6478
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_santhali_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeAnalysisStage
  - --analysis_doc_stats_parquets
  - gs://sangraha/spark_out/santhali/*/analysis/doc_stats/*/*/*.parquet
  - --analysis_viz_output
  - gs://sangraha/spark_out/santhali/visualization/dataset/analysis
  - --ana_viz_language
  - santhali
  - --ana_viz_gcp_bucket
  - sangraha
  - --viz_analysis_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 1417d4f6ec0d47b18b36c0b1048b3b16
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T19:50:55.501455Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T19:49:52.512439Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T19:49:52.536424Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T19:49:52.773608Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0055/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/a9d30f9216594bdea28d7a5c4b80f220/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/a9d30f9216594bdea28d7a5c4b80f220/driveroutput
jobUuid: b6307a6c-d5bf-39aa-a0a4-c28e7e760cf6
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_santhali_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeFilterStage
  - --filtered_docs_parquets
  - gs://sangraha/spark_out/santhali/*/filtered_docs/filtered_docs/*/*.parquet
  - --filter_viz_output
  - gs://sangraha/spark_out/santhali/visualization/dataset/filter
  - --fil_viz_gcp_bucket
  - sangraha
  - --viz_filter_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: a9d30f9216594bdea28d7a5c4b80f220
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T19:51:44.806401Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T19:50:58.647641Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T19:50:58.672682Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T19:50:58.929852Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0056/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/4ab1f04c7c69483ca0f98c5a479a8601/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/4ab1f04c7c69483ca0f98c5a479a8601/driveroutput
jobUuid: d23219c3-b169-36a3-841f-c4b51ccc2170
placement:
  clusterName: setu-debugging-50-highmem
  clusterUuid: d83f9aa0-6d42-4443-bcca-a8e58f2246c0
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_santhali_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --viz_cleaned_docs_parquets
  - gs://sangraha/spark_out_test/santhali/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --viz_symbol_heavy_parquets
  - gs://sangraha/spark_out_test/santhali/*/cleaned_docs/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out_test/santhali/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 4ab1f04c7c69483ca0f98c5a479a8601
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-10-02T09:24:57.163587Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-10-02T09:24:06.276792Z'
- state: SETUP_DONE
  stateStartTime: '2023-10-02T09:24:06.301220Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-10-02T09:24:06.620227Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-50-highmem-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696195790754_0045/
