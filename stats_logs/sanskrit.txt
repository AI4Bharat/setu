done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/d9ea2e6ea4024ac5bad8f4046bd8317c/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/d9ea2e6ea4024ac5bad8f4046bd8317c/driveroutput
jobUuid: 6f429c3c-8d64-3e66-9113-e16959f70ddf
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_sanskrit_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --symbol_heavy_parquets
  - gs://sangraha/spark_out/sanskrit/*/cleaned_docs/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out/sanskrit/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: d9ea2e6ea4024ac5bad8f4046bd8317c
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T21:10:44.070785Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T21:09:37.344205Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T21:09:37.367171Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T21:09:37.592218Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0077/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/3c90f9bd540e40e2b39a570b59cbaa94/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/3c90f9bd540e40e2b39a570b59cbaa94/driveroutput
jobUuid: fe647503-57e4-3ac5-80b9-29c3ba915f49
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_sanskrit_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeLIDStage
  - --lid_parquets
  - gs://sangraha/spark_out/sanskrit/*/lid_segregation/doc_lid/*/*/*.parquet
  - --cleaned_docs_parquets
  - gs://sangraha/spark_out/sanskrit/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --lid_viz_output
  - gs://sangraha/spark_out/sanskrit/visualization/dataset/lid
  - --lid_viz_gcp_bucket
  - sangraha
  - --viz_lid_stage_run_mode
  - stage
  - --viz_lid_perform_join
  - 'True'
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 3c90f9bd540e40e2b39a570b59cbaa94
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T21:11:59.137255Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T21:10:47.012285Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T21:10:47.038772Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T21:10:47.253585Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0078/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/f4560b30f7ab46e9a9926c35d73cd8fc/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/f4560b30f7ab46e9a9926c35d73cd8fc/driveroutput
jobUuid: a249f07e-e08b-3fb8-8931-b931836bc7fc
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_sanskrit_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeAnalysisStage
  - --analysis_doc_stats_parquets
  - gs://sangraha/spark_out/sanskrit/*/analysis/doc_stats/*/*/*.parquet
  - --analysis_viz_output
  - gs://sangraha/spark_out/sanskrit/visualization/dataset/analysis
  - --ana_viz_language
  - sanskrit
  - --ana_viz_gcp_bucket
  - sangraha
  - --viz_analysis_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: f4560b30f7ab46e9a9926c35d73cd8fc
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T21:13:59.886224Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T21:12:02.679724Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T21:12:02.702462Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T21:12:02.998323Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0079/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/15d02c701c324564bf0dad5470da2398/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/15d02c701c324564bf0dad5470da2398/driveroutput
jobUuid: af457511-99c6-3ce4-b1ec-45620dcad441
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_sanskrit_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeFilterStage
  - --filtered_docs_parquets
  - gs://sangraha/spark_out/sanskrit/*/filtered_docs/filtered_docs/*/*.parquet
  - --filter_viz_output
  - gs://sangraha/spark_out/sanskrit/visualization/dataset/filter
  - --fil_viz_gcp_bucket
  - sangraha
  - --viz_filter_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 15d02c701c324564bf0dad5470da2398
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T21:14:59.301658Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T21:14:03.111220Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T21:14:03.147658Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T21:14:03.531966Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0080/
