done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/17d266eeefaa4a94887e8feed4b9dec7/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/17d266eeefaa4a94887e8feed4b9dec7/driveroutput
jobUuid: fdf3deec-dc56-3c80-b3ea-1d8214321dab
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_hindi_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --symbol_heavy_parquets
  - gs://sangraha/spark_out/hindi/*/cleaned_docs/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out/hindi/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 17d266eeefaa4a94887e8feed4b9dec7
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T20:14:05.957105Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T20:13:08.728781Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T20:13:08.755719Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T20:13:09.529739Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0065/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/aa77bd72e2e142869452bfc064a5a77c/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/aa77bd72e2e142869452bfc064a5a77c/driveroutput
jobUuid: e2b045e0-816e-37b7-9104-8cde3cc2f0ca
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_hindi_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeLIDStage
  - --lid_parquets
  - gs://sangraha/spark_out/hindi/*/lid_segregation/doc_lid/*/*/*.parquet
  - --cleaned_docs_parquets
  - gs://sangraha/spark_out/hindi/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --lid_viz_output
  - gs://sangraha/spark_out/hindi/visualization/dataset/lid
  - --lid_viz_gcp_bucket
  - sangraha
  - --viz_lid_stage_run_mode
  - stage
  - --viz_lid_perform_join
  - 'True'
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: aa77bd72e2e142869452bfc064a5a77c
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T20:22:11.369729Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T20:14:08.416114Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T20:14:08.440772Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T20:14:08.695987Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0066/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/f8ecca92dd5544be85ab5bb5c502fa6d/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/f8ecca92dd5544be85ab5bb5c502fa6d/driveroutput
jobUuid: 797fa845-296c-35a7-b7e7-56f7280f9c07
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_hindi_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeAnalysisStage
  - --analysis_doc_stats_parquets
  - gs://sangraha/spark_out/hindi/*/analysis/doc_stats/*/*/*.parquet
  - --analysis_viz_output
  - gs://sangraha/spark_out/hindi/visualization/dataset/analysis
  - --ana_viz_language
  - hindi
  - --ana_viz_gcp_bucket
  - sangraha
  - --viz_analysis_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: f8ecca92dd5544be85ab5bb5c502fa6d
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T20:46:58.374414Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T20:22:14.728702Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T20:22:14.754143Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T20:22:15.133396Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0067/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/6662b9fd2efd4867bc4aa443d6ee6fb1/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/6662b9fd2efd4867bc4aa443d6ee6fb1/driveroutput
jobUuid: a00fc4b7-3b6c-3802-ba0e-cb3d4a7d61df
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_hindi_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeFilterStage
  - --filtered_docs_parquets
  - gs://sangraha/spark_out/hindi/*/filtered_docs/filtered_docs/*/*.parquet
  - --filter_viz_output
  - gs://sangraha/spark_out/hindi/visualization/dataset/filter
  - --fil_viz_gcp_bucket
  - sangraha
  - --viz_filter_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 6662b9fd2efd4867bc4aa443d6ee6fb1
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T20:48:02.657571Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T20:47:02.070099Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T20:47:02.097412Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T20:47:02.494725Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0068/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/e469cf27931d4d2fa8df9177dffc12c5/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/e469cf27931d4d2fa8df9177dffc12c5/driveroutput
jobUuid: 8820ed34-3eab-309e-8354-8b3c5ab1edfc
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_hindi_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeLIDStage
  - --lid_parquets
  - gs://sangraha/spark_out/hindi/*/lid_segregation/doc_lid/*/*/*.parquet
  - --cleaned_docs_parquets
  - gs://sangraha/spark_out/hindi/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --lid_viz_output
  - gs://sangraha/spark_out/hindi/visualization/dataset/lid
  - --lid_viz_gcp_bucket
  - sangraha
  - --viz_lid_stage_run_mode
  - stage
  - --viz_lid_perform_join
  - 'True'
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: e469cf27931d4d2fa8df9177dffc12c5
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-30T13:14:46.336764Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-30T13:06:00.266301Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-30T13:06:00.302374Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-30T13:06:00.770841Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696078943812_0002/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/8c8d441df830464da19544eaf3c14224/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/8c8d441df830464da19544eaf3c14224/driveroutput
jobUuid: 0c9b149c-6310-37df-94ae-251b35f7dc8e
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_hindi_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeLIDStage
  - --lid_parquets
  - gs://sangraha/spark_out/hindi/*/lid_segregation/doc_lid/*/*/*.parquet
  - --cleaned_docs_parquets
  - gs://sangraha/spark_out/hindi/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --lid_viz_output
  - gs://sangraha/spark_out/hindi/visualization/dataset/lid
  - --lid_viz_gcp_bucket
  - sangraha
  - --viz_lid_stage_run_mode
  - stage
  - --viz_lid_perform_join
  - 'True'
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 8c8d441df830464da19544eaf3c14224
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-30T13:36:28.591642Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-30T13:28:11.749212Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-30T13:28:11.779848Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-30T13:28:12.024977Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696078943812_0004/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/bfe2315f749d48919c4c4ffabbe6089b/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/bfe2315f749d48919c4c4ffabbe6089b/driveroutput
jobUuid: 04df6587-7ce1-335f-a01d-d8b76d7e5987
placement:
  clusterName: setu-debugging-50-highmem
  clusterUuid: d83f9aa0-6d42-4443-bcca-a8e58f2246c0
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_hindi_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --viz_cleaned_docs_parquets
  - gs://sangraha/spark_out_test/hindi/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --viz_symbol_heavy_parquets
  - gs://sangraha/spark_out_test/hindi/*/cleaned_docs/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out_test/hindi/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: bfe2315f749d48919c4c4ffabbe6089b
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-10-02T09:11:21.352526Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-10-02T09:09:13.855602Z'
- state: SETUP_DONE
  stateStartTime: '2023-10-02T09:09:13.876311Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-10-02T09:09:14.171155Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-50-highmem-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696195790754_0033/
