done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/30b77d41e8e6436c8909f54a44d501a5/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/30b77d41e8e6436c8909f54a44d501a5/driveroutput
jobUuid: cd41f1c5-82d7-3423-bff8-dcde816f625b
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_dogri_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --symbol_heavy_parquets
  - gs://sangraha/spark_out/dogri/*/lid_segregation/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out/dogri/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 30b77d41e8e6436c8909f54a44d501a5
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T18:58:17.347681Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T18:57:30.653152Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T18:57:30.676639Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T18:57:30.928494Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0013/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/d7a875a87afa42e09a073d155a3040a1/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/d7a875a87afa42e09a073d155a3040a1/driveroutput
jobUuid: 6ecd76c4-b4e5-39e6-b172-e1b424255adf
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_dogri_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeLIDStage
  - --lid_parquets
  - gs://sangraha/spark_out/dogri/*/lid_segregation/doc_lid/*/*/*.parquet
  - --cleaned_docs_parquets
  - gs://sangraha/spark_out/dogri/*/lid_segregation/doc_lid/*/*.parquet
  - --lid_viz_output
  - gs://sangraha/spark_out/dogri/visualization/dataset/lid
  - --lid_viz_gcp_bucket
  - sangraha
  - --viz_lid_stage_run_mode
  - stage
  - --viz_lid_perform_join
  - 'False'
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: d7a875a87afa42e09a073d155a3040a1
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T18:59:12.375341Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T18:58:20.359851Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T18:58:20.386364Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T18:58:20.628640Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0014/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/c99fbab2d29c4b7a8f702ef76583d085/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/c99fbab2d29c4b7a8f702ef76583d085/driveroutput
jobUuid: 326d0f1f-9c1b-3939-8dbf-097fe1c68631
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_dogri_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeAnalysisStage
  - --analysis_doc_stats_parquets
  - gs://sangraha/spark_out/dogri/*/analysis/doc_stats/*/*/*.parquet
  - --analysis_viz_output
  - gs://sangraha/spark_out/dogri/visualization/dataset/analysis
  - --ana_viz_language
  - dogri
  - --ana_viz_gcp_bucket
  - sangraha
  - --viz_analysis_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: c99fbab2d29c4b7a8f702ef76583d085
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T19:00:17.421408Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T18:59:15.276563Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T18:59:15.301337Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T18:59:15.547055Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0015/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/99e4e9f2eb5f4ba5a040ed3bc1abbcdd/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/1a2e69ec-be5e-4e99-994b-2a0587fa8d91/jobs/99e4e9f2eb5f4ba5a040ed3bc1abbcdd/driveroutput
jobUuid: 0b7d8024-0794-384e-867e-fd558745c9d5
placement:
  clusterName: setu-debugging-15
  clusterUuid: 1a2e69ec-be5e-4e99-994b-2a0587fa8d91
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_dogri_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeFilterStage
  - --filtered_docs_parquets
  - gs://sangraha/spark_out/dogri/*/filtered_docs/filtered_docs/*/*.parquet
  - --filter_viz_output
  - gs://sangraha/spark_out/dogri/visualization/dataset/filter
  - --fil_viz_gcp_bucket
  - sangraha
  - --viz_filter_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: 99e4e9f2eb5f4ba5a040ed3bc1abbcdd
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-09-29T19:01:08.361361Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-09-29T19:00:21.137229Z'
- state: SETUP_DONE
  stateStartTime: '2023-09-29T19:00:21.166421Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-09-29T19:00:21.509679Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-15-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696011833167_0016/
done: true
driverControlFilesUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/b74130533dc54d628086cec1767c2cb6/
driverOutputResourceUri: gs://dataproc-staging-asia-south1-690617486206-30otkfwr/google-cloud-dataproc-metainfo/d83f9aa0-6d42-4443-bcca-a8e58f2246c0/jobs/b74130533dc54d628086cec1767c2cb6/driveroutput
jobUuid: 4a11f0bc-e64f-30fb-9a04-dfd4b896015a
placement:
  clusterName: setu-debugging-50-highmem
  clusterUuid: d83f9aa0-6d42-4443-bcca-a8e58f2246c0
pysparkJob:
  args:
  - --config
  - gs://sangraha/setu/dataproc/configs/spark_dogri_config.json
  - --mode
  - ocr
  - --run_local
  - 'False'
  - VisualizeDocCleanStage
  - --viz_cleaned_docs_parquets
  - gs://sangraha/spark_out_test/dogri/*/cleaned_docs/cleaned_docs/*/*.parquet
  - --viz_symbol_heavy_parquets
  - gs://sangraha/spark_out_test/dogri/*/cleaned_docs/symbol_heavy/*/*.parquet
  - --doc_clean_viz_output
  - gs://sangraha/spark_out_test/dogri/visualization/dataset/doc_clean
  - --dc_viz_gcp_bucket
  - sangraha
  - --viz_dc_stage_run_mode
  - stage
  loggingConfig:
    driverLogLevels:
      __main__: DEBUG
      root: FATAL
  mainPythonFileUri: gs://sangraha/setu/setu/run.py
  properties:
    spark.driver.memory: 30g
    spark.executor.cores: '12'
    spark.executor.memory: 50g
    spark.submit.deployMode: client
  pythonFileUris:
  - gs://sangraha/setu/dataproc/envs/setu.zip
reference:
  jobId: b74130533dc54d628086cec1767c2cb6
  projectId: sangraha-396106
status:
  state: DONE
  stateStartTime: '2023-10-02T09:06:21.133160Z'
statusHistory:
- state: PENDING
  stateStartTime: '2023-10-02T09:05:23.524397Z'
- state: SETUP_DONE
  stateStartTime: '2023-10-02T09:05:23.549280Z'
- details: Agent reported job success
  state: RUNNING
  stateStartTime: '2023-10-02T09:05:23.846218Z'
yarnApplications:
- name: Sangraha Anaylsis
  progress: 1.0
  state: FINISHED
  trackingUrl: http://setu-debugging-50-highmem-m.asia-south1-a.c.sangraha-396106.internal.:8088/proxy/application_1696195790754_0030/
